[lsp]
# task_list: list of workloads to be executed, separated by comma
# exec_mode: sequential/concurrency
task_list = tpch-ao-co, tpch-ao-part, tpch-parquet-10G, tpch-parquet-part-10G, tpch-parquet-100G, tpch-parquet-part-100G, sri-parquet, sri-parquet-part, sri-ao-co, sri-ao-part, fts, copy
exec_mode = concurrency


[tpch-ao-co]
# dbname: name of database to run TPC-H
# niteration: number of iterations to run TPC-H
# load_data: flag: True to load TPC-H data, False to skip data loading
#            data_size: GB/host
# table_setting: flag: True for AO, False for Heap
#                orientation: row/column/parquet
#                pagesize: only for parquet, default value is 1048576B (1MB)
#                rowgroupsize: only for parquet, default value is 8388608B (8MB)
#                compression type: zlib/quicklz for AO tables, snappy/gzip for parquet
#                compression level: only 1 for quicklz, 1~9 for zlib
#                partition: True to with 128 partitions, False to without partitions
# run_workloads: flag: True to run TPC-H, False to skip TPC-H query execution
#                nconcurrency: concurrency of TPC-H workloads execution
#                query_order: order of TPC-H queries, SEQUENTIAL/RANDOM
dbname = gpsqltest
niteration = 2
load_data = True, 100
table_setting = True, COLUMN, 1048576, 8388608, QuickLZ, 1, False
run_workloads = True, 5, RANDOM


[tpch-ao-part]
dbname = gpsqltest
niteration = 1
load_data = True, 100
table_setting = True, ROW, 1048576, 8388608, QuickLZ, 1, True
run_workloads = True, 5, RANDOM


[sri-ao-co]
# ntables: number: number of tables to be created
#          method: create table methond,concurrency/sequential
# ninserts: number: number of inserts
#           distribute method: the inserts distribute flag: even/skew
#run_workloads: flag: True to run SRI, False only create tables
#               nconcurrency: concurrency of SRI workloads execution
#               query_order: order of SRI queries, SEQUENTIAL/RANDOM
dbname = gpsqltest
niteration = 5
load_data = True
ntables = 2, concurrency
ninserts = 100, even
table_setting = True, COLUMN, 1048576, 8388608, QuickLZ, 1, False
run_workloads = True, 10, RANDOM


[sri-ao-part]
dbname = gpsqltest
niteration = 1
load_data = True
ntables = 2, concurrency
ninserts = 100, even
table_setting = True, ROW, 1048576, 8388608, QuickLZ, 1, True
run_workloads = True, 10, RANDOM


[fts]
dbname = gpsqltest_fts
niteration = 10
load_data = True, 10
table_setting = True, ROW, 1048576, 8388608, QuickLZ, 1, False
run_workloads = True, 1, RANDOM


[copy]
dbname = gpsqltest
niteration = 10
load_data = True
table_setting = True, ROW, 1048576, 8388608, QuickLZ, 1, True
run_workloads = True, 1, RANDOM


[dsq]
dbname = gpsqltest
niteration = 1
load_data = True
size = 3
run_workloads = True, 1, RANDOM


[madlib]
dbname = gpsqltest
niteration = 1
load_data = True
run_workloads = True, 20, RANDOM


[tpch-parquet-10G]
dbname = gpsqltest_tpch_parquet_10G
niteration = 2
load_data = True, 10
table_setting = True, PARQUET, 1048576, 8388608, SNAPPY, 0, False
run_workloads = True, 5, RANDOM


[tpch-parquet-part-10G]
dbname = gpsqltest_tpch_parquet_part_10G
niteration = 1
load_data = True, 10
table_setting = True, PARQUET, 1048576, 8388608, GZIP, 1, True
run_workloads = True, 5, RANDOM


[tpch-parquet-100G]
dbname = gpsqltest_tpch_parquet_100G
niteration = 1
load_data = True, 100
table_setting = True, PARQUET, 1048576, 8388608, None, 0, False
run_workloads = True, 2, RANDOM


[tpch-parquet-part-100G]
dbname = gpsqltest_tpch_parquet_part_100G
niteration = 1
load_data = True, 100
table_setting = True, PARQUET, 1048576, 8388608, SNAPPY, 0, True
run_workloads = True, 2, RANDOM


[sri-parquet]
dbname = gpsqltest
niteration = 5
load_data = True
ntables = 2, concurrency
ninserts = 100, even
table_setting = True, PARQUET, 1048576, 8388608, None, 0, False
run_workloads = True, 5, RANDOM


[sri-parquet-part]
dbname = gpsqltest
niteration = 5
load_data = True
ntables = 2, concurrency
ninserts = 100, even
table_setting = True, PARQUET, 1048576, 8388608, None, 0, True
run_workloads = True, 5, RANDOM
